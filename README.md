# Practicum_project
Проекты над которыми я работала в яндекс практикуме

# Анализ А/В-теста и проверка гипотез по росту выручки крупного интернет-магазина
У нас есть данные по заказам и количеству пользователей за каждый день августа 2019 года, полученные по результатам проведенного А/В-теста. В дополнении у нас имеются данные о 9 гипотезах по доходам интернет-магазина.

**Цель проекта:** Принять решение по результатам проведенного А/В-теста — остановить тест (и оценить результаты) или завершить.

**Для достижения данной цели мы поставили следующие задачи:** 1. Указать, как изменилась гипотеза приоритетности при применении RICE вместо ICE. Объясните, почему так произошло. 2. Постройте графики кумулятивной выручки и среднего чека по группам, относительного изменения кумулятивного среднего чека и среднего количества заказов группы B к группе A, кумулятивного среднего количества заказов для посетителей по группам, точечного графика количества заказов и стоимости заказов для пользователей. 3. Посчитайте 95-й и 99-й проценты количества заказов для пользователя и стоимости заказов. 4. Выбрать страну для определения аномальных пользователей и отфильтровать данные. 5. Подсчитать статистическую трансформацию в среднем количестве заказов для посетителей и среднем чеке заказов между документами по «сырым» и отфильтрованным данным. 5. Принять решение по результатам теста — остановить тест (оценить результаты) или продолжить тест.

**Описание данных:** у нас есть три файла с данными — один хранит описание 9-ти гипотез (с параметрами охват, влияние, уверенность, усилие); второй — информация о заказах в интернет-магазине за август 2019 года; третий — информация о количестве пользователей в указанной группе.

**Краткий план работы:**
Чтобы правильно решить поставленные задачи и придти к поставленной цели, нам предварительно надо: 1. Открыть файлы и провести первый просмотр данных. 2. Провести предобработку данных (обдумать пропуски, дубликаты (явные и неявные), проверить формат данных, проверить ошибки в данных, изучить аномальные данные и принять решение, удалить их или нет). 3. Провести исследовательский анализ данных — изучить данные по дате, выручке, группе, количеству пользователей, просмотреть показатели данных (мин, максимум, медиану, среднюю, квартили и т. д.), а также изучить связь некоторых данных между ними. 4. Постройте и проведите анализ графиков. 5. Отфильтровать аномальные данные. 6. Провестистатистический анализ. 6. Сделайте выводы.

#используемые в проекте библиотеки: pandas, scipy.stats, numpy, matplotlib.pyplot, datetime.datetime, datetime.timedelta

# Анализ бизнес-показателей кампании Procrastinate Pro+
Мы имеем данные о пользователях развлекательного приложения Procrastinate Pro+, привлеченных с 1 мая по 27 октября 2019 года (лог сервера с данными об их посещениях, выгрузка их покупок за этот период). А также данные о рекламных расходах.

**Цель проекта:** выяснить, почему компания терпит неудачу, несмотря на огромные вложения в рекламу, и помочь компании выйти в плюс.

**Для выполнения данной цели мы поставили следующие задачи:** 1.) Откуда приходят пользователи и какими устройствами они пользуются 2.) Сколько стоит привлечение пользователей из различных рекламных каналов 3.) Сколько денег приносит каждый клиент 4.) Когда расходы на привлечение клиента окупаются 5.) Какие факторы мешают привлечению клиентов

**Описание данных:** у нас есть три файла с данными - один хранит журнал сервера с информацией о посещениях сайта; второй - информация о заказах; третья - информация о расходах на рекламу.

**Краткий план работы:**
Чтобы выбрать поставленные задачи и придти к поставленным целям, нам предварительно необходимо: 1) Открыть файлы и провести первичный просмотр данных 2) Провести предобработку данных (явные и неявные), проверить формат данных, проверить данные, определить их аномальные данные и решить, выявить их или нет) 3) Провести исследовательский анализ данных - проверить данные по устройствам, региону, каналам, определить распределение данных (мин, макс, медиану, основные, квартили и т.д.), а также обратите внимание на некоторые данные между собой. 4) провести маркетинговый анализ 5) оценить окупаемость рекламы 6) сделать выводы

#используемые в проекте библиотеки: pandas, numpy, datetime.datetime, datetime.timedelta, matplotlib.pyplot, seaborn

# Анализ данных по продажам игр и их характеристикам в разных регионах с 1980 по 2016 гг. 
Мы имеем данные о продажах игр и их характеристиках в разных регионах.

**Цель проекта:** выявить определяющие успешность игры закономерности, для того чтобы спланировать будущую рекламную компанию 2017 года. 

*Это позволит сделать ставку на потенциально популярный продукт и спланировать рекламные компании.

**Для выполнения данной цели нам поставили следующие задачи:** 
1.) Определить актуальный период
2.) Выявить наиболее популярные платформы в актуальном периоде, в целом и по регионам
3.) Определить популярные жанры в актуальном периоде, в целом и по регионам
4.) Определить как влияют оценки критиков и пользователей на продажи игр в актуальном периоде,
5.) Выявить наиболее популярные возрастные категории игр в актуальном периоде, в целом и по регионам

**Описание данных:** У нас есть один файл с данными об играх, платформах, годах выпуска игр, жанрах, продажах игр в разных регионах (Северная Америка, Европа, Япония и другие страны, в миллионах копий), оценках критиков и пользователей и данные о возрастной категории игр (по организации ESBR). 

**Краткий план работы:**
Чтобы выполнить поставленные задачи и придти к намеченой цели, нам предварительно надо: 1) Открыть файлы и провести первичный просмотр данных 2) Провести предобработку данных (проанализировать пропуски, дубликаты (явные и неявные), проверить формат данных, проверить ошибки в данных, проанализировать аномальные данные и решить, удалять их или нет) 3) Провести исследовательский анализ данных - проанализировать данные по платформам, годам выпуска, жанрам, продажам в разных регионах, оценкам критиков и пользователей и данные по возрастной категории, посмотреть распределение данных (min, max, медиану, среднюю, квартили и т.д.), а также проанализировать связь некоторых данных между собой. 4) Посчитать промежуточные величины, необходимые нам для выполнения поставленных задач. 5) Провести статистический анализ данных 6) Сделать выводы

#используемые в проекте библиотеки: pandas, datetime, matplotlib.pyplot, numpy, seaborn, scipy.stats

# Анализ информации о пользователях сервиса аренды самокатов GoFast и их поездках

Для совершения поездки на самокате пользователи используют мобильное приложение. Сервисом можно пользоваться без подписки и с подпиской.

**Цель проекта:** выяснить - приносят ли сервису выгоду пользователи с подпиской, по сравнению с пользователями без подписки

**Для выполнения данной цели нам поставили следующие задачи, требуется выяснить:** 1.) тратят ли пользователи с подпиской больше времени на поездки. 2.) Оптимально ли используется самокат пользователями с подпиской (проветить - среднее растояние пользователей с подпиской не более 3130 м.) 3.) выяснить - будет ли помесячная выручка пользователей с подпиской выше, чем у пользователей без подписки

**Описание данных:** У нас есть три файла с данными о пользователях, их поездках и их подписках в ряде городов России. Первый фаил включает в себя: id-пользователя, его имя, возраст, город и тип подписки. Второй файл: помимо id, имеет расстояние которое пользователь проехал в текущей сессии (в метрах), продолжительность сессии (в минутах) и дата совершения поездки. Третий файл - дает информацию о типе подписки для каждого пользователя и условия по оплате.

**Краткий план работы:**
Что бы выполнить поставленные задачи и придти к намеченой цели нам предварительно надо: 1) Открытьт файлы и провести первичный просмотр данных 2) Провести предобработку данных (проанализировать пропуски, дубликаты (явные и не явные), формат данных, проверить ошибки в данных, проанализировать аномальные данные и решить удалять их или нет) 3) Провести исследовательский анализ данных - проанализировать данные по расстоянию и длительности поездок, по возрасту и городам пользователей, посмотреть распределение данных (min, max, медиану, среднюю, квартили и т.д.). 4) Посчитать промежуточные величины необходимые нам для выполнения поставленых задач. 5) Провести статистический анализ данных 6) Сделать выводы

#используемые в проекте библиотеки: pandas, matplotlib.pyplot, numpy, scipy.stats

# Выявление профиля потребления интернет-магазина товаров для дома и быта "Пока все еще тут"
У нас есть датасет с описанием транзикций интернет-магазина «Пока все еще тут».

**Цель проекта:** сегментировать покупателей по профилю потребления.

**Бизнес-задачи:** 1. Создание помесячных предложений категорий товаров для каждого покупателя; 2. Увеличение продаж; 3. Возвращение ушедших клиентов.

**Для выполнения целевой цели необходимо решить следующие задачи:** 1. Сегментация товаров по признаку товаров к той или иной товарной категории; 2. Анализ динамики выручки; 3. Анализ среднего чека и его динамика; 4. Анализ помесячной динамики средней выручки покупателя; 5. Сегментация покупателей; 6. Анализ сегментов покупателей (к-во покупок, средний чек, основные товары и категории); 7. Анализ категорий товаров и их сезонности по выделенным сегментам покупателей.

**Описание данных:** У нас есть один файл с данными — в нем представлена ​​транзикции интернет-магазина «Пока все еще тут». Даны: дата заказа, идентификатор покупателя, идентификатор заказа, наименование товара, к-во товара в заказе, цена товара.

#используемые в проекте библиотеки: pandas, datetime.timedelta, matplotlib.pyplot, numpy, scipy.stats, seaborn

# Изучение поведения пользователей и анализ A/А/В-теста интернет-магазина продуктов питания
У нас есть данные за определенный период из лога приложения нашего магазина продуктов питания.

**Цель проекта:** проанализировать поведение пользователей и принять решение по результатам проведенного А/А/В-теста (влияют ли новые шрифты в приложении на поведение пользователей).

**Для выполнения данной цели нам поставили следующие задачи:** 1. Изучить статистику количества событий и пользователей в логе 2. Понять, за какой период мы имеем данные, и проанализировать распределение пользователей и событий по датам 3. Проанализировать распределение событий и пользователей по группам 4. Построить и изучить воронку событий 5. Посчитать статистическую значимость различий в долях по каждому типу событий в каждой группе 6. Принять решение по результатам теста о влиянии нового шрифта на поведение пользователей приложения магазина продуктов питания.

**Описание данных:** у нас есть один файл с данными — он хранит информацию из лога нашего приложения. В нем указано для каждого события: название события, идентификатор пользователя, совершившего это событие, время события и номер эксперимента, к которому это событие относится.

**Краткий план работы:**
Чтобы выполнить поставленные задачи и придти к намеченной цели, нам предварительно надо: 1. Открыть файлы и провести первичный просмотр данных. 2. Провести предобработку данных (проанализировать пропуски, дубликаты (явные и неявные), проверить формат данных, проверить ошибки в данных, проанализировать аномальные данные и решить, удалять их или нет). 3. Провести исследовательский анализ данных — проанализировать данные по дате, количеству событий, группе, количеству пользователей, посмотреть распределение данных (min, max, медиану, среднюю, квартили и т.д.), а также проанализировать связь некоторых данных между собой. 4. Построить и изучить воронку событий 5. Изучить результаты эксперимента. 6. Провести статистический анализ. 6. Сделать выводы.

#используемые в проекте библиотеки: pandas, scipy.stats, numpy, matplotlib.pyplot, datetime.datetime, datetime.timedelta, datetime.timezone, seaborn, math, plotly.graph_objects, statsmodels.api

# Исследование объявлений о продаже квартир
В нашем распоряжении данные сервиса Яндекс Недвижимость — архив объявлений о продаже квартир в Санкт-Петербурге и соседних населённых пунктах за несколько лет. Нам нужно научиться определять рыночную стоимость объектов недвижимости. Для этого проведем исследовательский анализ данных и установим параметры, влияющие на цену объектов. Это позволит построить автоматизированную систему: она отследит аномалии и мошенническую деятельность.

По каждой квартире на продажу доступны два вида данных. Первые вписаны пользователем, вторые — получены автоматически на основе картографических данных. Например, расстояние до центра, аэропорта и других объектов — эти данные автоматически получены из геосервисов. Количество парков и водоёмов также заполняется без участия пользователя.

#используемые в проекте библиотеки: pandas

# Исследование рынка заведений общественного питания Москвы на лето 2022 года.
У нас есть датасет с заведениями общественного питания Москвы, созданный на основе данных сервисов Яндекс Карты и Яндекс Бизнес на лето 2022 года.

**Цель проекта:** проанализировать рынок заведений общественного питания Москвы на лето 2022 года, найти интересные особенности и презентовать полученные результаты, которые в будущем помогут в выборе подходящего инвесторам места.

**Для выполнения данной цели нам поставили следующие задачи:** 1. Изучить количество объектов по категориям, районам, ценовым категориям, посадочным местам, среднему чеку, по рейтингу и т.д. 2. Понять взаимосвязь между рядом показателей 3. Проанализировать распределение заведений на карте и оценить связи разных показателей с местоположением заведения 4. Найти топ-15 улиц по количеству заведений 5. Найти особенности заведений расположенных по одному на улице.

**Описание данных:**
У нас есть один файл с данными — он создан созданный на основе данных сервисов Яндекс Карты и Яндекс Бизнес. В нем указано для каждого заведения: название, адрес, категория заведения, информация о днях и часах работы, координаты заведения, рейтинг, категория цен, средняя стоимость заказа, стоимость чашки капучино, средний чек, информация является ли заведение сетевым, а так же количество посадочных мест.

**Краткий план работы:**
Чтобы выполнить поставленные задачи и придти к намеченной цели, нам предварительно надо: 1. Открыть файлы и провести первичный просмотр данных. 2. Провести предобработку данных (проанализировать пропуски, дубликаты (явные и неявные), проверить формат данных, проверить ошибки в данных, проанализировать аномальные данные и решить, удалять их или нет). 3. Провести исследовательский анализ данных — проанализировать данные по категориям, по месторасположению, по среднему чеку, количеству посадочных мест, а также проанализировать связь некоторых данных между собой. 4. Выделить топ-15 сетей, выделить топ-15 улиц (по количеству заведений), выделить заведения расположенные по одному на улице, оценить особенности этих групп заведений. 5. Оценить связь стоимости среднего чека и расстояния. 6.Провести статистический анализ. 7. Сделать выводы.

#используемые в проекте библиотеки: pandas, scipy.stats, numpy, matplotlib.pyplot, datetime.datetime, datetime.timedelta,datetime.timezone, seaborn, math, plotly.graph_objects, statsmodels.api, folium.Map, folium.Marker, folium.Choropleth, folium.plugins.MarkerCluster, json, random.randint, geopy.distance
